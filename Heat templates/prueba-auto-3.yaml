heat_template_version: 2015-04-30

description: >
  This is a very simple template that illustrates the basic features
  of OS::Heat::AutoScalingGroup when the scaled resource is an
  OS::Nova::Server.  By virtue of its simplicity this example should
  be usable in many contexts.  In particular, this example does not
  require Neutron nor a load balancer nor any particular support for
  software in the VMs.  In fact, the VMs in this example do not
  actually do anything.  This example does no automatic scaling, but
  does discuss manual scaling.
  For a more complete example, see autoscaling.yaml.
parameters:
  key_name:
    type: string
    description: Name of an existing key pair to use for the instances
    default: prueba-keypair
    constraints:
      - custom_constraint: nova.keypair
        description: Must name a public key (pair) known to Nova
  flavor:
    type: string
    description: Flavor for the instances to be created
    default: m1.little
    constraints:
      - custom_constraint: nova.flavor
        description: Must be a flavor known to Nova
  image:
    type: string
    description: >
      Name or ID of the image to use for the instances.
      You can get the default from
      http://cloud.fedoraproject.org/fedora-20.x86_64.qcow2
      There is also
      http://cloud.fedoraproject.org/fedora-20.i386.qcow2
      Any image should work since this template
      does not ask the VMs to do anything.
    default: prueba-cirros
    constraints:
      - custom_constraint: glance.image
        description: Must identify an image known to Glance
  network:
    type: string
    description: The network for the VM
    default: net_mgmt
  volume:
    type: OS::Cinder::Volume
    properties:
    image: 'prueba-cirros'
    size: 2

resources:
  asg:
    type: OS::Heat::AutoScalingGroup
    properties:
      resource:
        server:
          type: OS::Nova::Server
          properties:
            key_name: { get_param: key_name }
            image: { get_param: image }
            flavor: { get_param: flavor }
            networks: [{network: {get_param: network} }]
            metadata: {"metering.server_group": {get_param: "OS::stack_id"}}
            block_device_mapping:
              - device_name: vda
                delete_on_termination: true
                volume_id: { get_resource: volume } 
            user_data_format: RAW
            user_data: |
              #!/bin/sh
              while [ 1 ] ; do echo $((13**99)) 1>/dev/null 2>&1; done &            
      cooldown: 60
      min_size: 1
      desired_capacity: 2
      max_size: 6
      rolling_updates:
        min_in_service: 1
        max_batch_size: 1
        pause_time: 10

  scale_up_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: {get_resource: asg}
      cooldown: 60
      scaling_adjustment: 1


  scale_down_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: {get_resource: asg}
      cooldown: 60
      scaling_adjustment: '-1'

  cpu_alarm_high:
    type: OS::Aodh::GnocchiAggregationByResourcesAlarm
    properties:
      description: Scale up if CPU > 80%
      metric: cpu_util
      aggregation_method: mean
      granularity: 300
      evaluation_periods: 1
      threshold: 80
      resource_type: instance
      comparison_operator: gt
      alarm_actions:
        - str_replace:
            template: trust+url
            params:
              url: {get_attr: [scale_up_policy, signal_url]}
      query:
        list_join:
          - ''
          - - {'=': {server_group: {get_param: "OS::stack_id"}}}

  cpu_alarm_low:
    type: OS::Aodh::GnocchiAggregationByResourcesAlarm
    properties:
      description: Scale down if CPU < 15% for 5 minutes
      metric: cpu_util
      aggregation_method: mean
      granularity: 300
      evaluation_periods: 1
      threshold: 15
      resource_type: instance
      comparison_operator: lt
      alarm_actions:
        - str_replace:
            template: trust+url
            params:
              url: {get_attr: [scale_up_policy, signal_url]}
      query:
        list_join:
          - ''
          - - {'=': {server_group: {get_param: "OS::stack_id"}}}

outputs:
  scale_up_url:
    description: >
      This URL is the webhook to scale up the group.  You can invoke
      the scale-up operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [scale_up_policy, alarm_url]}
  scale_dn_url:
    description: >
      This URL is the webhook to scale down the group.  You can invoke
      the scale-down operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [scale_down_policy, alarm_url]}
  asg_size:
    description: >
      This is the current size of the auto scaling group.
    value: {get_attr: [asg, current_size]}
  server_list:
    description: >
      This is a list of server names that are part of the group.
    value: {get_attr: [asg, outputs_list, name]}
  networks:
    description: >
      This is a map of server resources and their networks.
    value: {get_attr: [asg, outputs, networks]}
  gnocchi_query:
    value:
      str_replace:
        template: >
          gnocchi measures aggregation --resource-type instance
          --query 'server_group="stackval"'
          --granularity 300 --aggregation mean -m cpu_util
        params:
          stackval: { get_param: "OS::stack_id" }
  server_ips:
    description: >
      This is a list of first ip addresses of the servers in the group
      for a specified network.
    value: {get_attr: [asg, outputs_list, networks, {get_param: network}, 0]}
